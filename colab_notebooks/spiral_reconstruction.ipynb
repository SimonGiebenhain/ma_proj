{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spiral_reconstruction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzssNI-6UrP2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "%cd '/content/gdrive/My Drive/ma_proj'\n",
        "!git pull"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_B46uQTWkPR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "print('PyTorch version: {}'.format(torch.__version__))\n",
        "\n",
        "!pip install torch-scatter==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
        "!pip install torch-sparse==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
        "!pip install torch-cluster==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
        "!pip install torch-spline-conv==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
        "!pip install torch-geometric\n",
        "\n",
        "%cd ..\n",
        "%cd '/content/gdrive/My Drive/'\n",
        "!ls\n",
        "# overwrite coalesce.py and storage.py in torch_sparse, such that torch.short edge indices are supported to safe memory when loading data\n",
        "!cp torch_sparse/coalesce.py /usr/local/lib/python3.6/dist-packages/torch_sparse/coalesce.py\n",
        "!cp torch_sparse/storage.py /usr/local/lib/python3.6/dist-packages/torch_sparse/storage.py\n",
        "!cp torch_sparse/tensor.py /usr/local/lib/python3.6/dist-packages/torch_sparse/tensor.py\n",
        "!cp torch_geometric/data/data.py /usr/local/lib/python3.6/dist-packages/torch_geometric/data/data.py\n",
        "\n",
        "!pip install openmesh\n",
        "\n",
        "cd mesh\n",
        "\n",
        "!BOOST_INCLUDE_DIRS=/usr/include/boost make all\n",
        "\n",
        "%cd ../ma_proj/spiralnet_plus/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cF2QVGMKeZfg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import argparse\n",
        "import os\n",
        "import os.path as osp\n",
        "from easydict import EasyDict\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch_geometric.transforms as T\n",
        "from psbody.mesh import Mesh\n",
        "\n",
        "from reconstruction import AE, VAE, run, eval_error, test\n",
        "from datasets import MeshData\n",
        "from utils import utils, writer, DataLoader, mesh_sampling\n",
        "\n",
        "args = EasyDict()\n",
        "args.exp_name = 'interpolation_exp'\n",
        "args.dataset = 'CoMA'\n",
        "args.split = 'interpolation'\n",
        "args.test_exp = 'bareteeth'\n",
        "args.n_threads = 4\n",
        "args.device_idx = 0\n",
        "\n",
        "# network hyperparameters\n",
        "args.out_channels = [32, 32, 32, 64]\n",
        "args.latent_channels = 16\n",
        "args.in_channels = 3\n",
        "args.seq_length = [9,9,9,9]\n",
        "args.dilation = [1, 1, 1, 1]\n",
        "\n",
        "# optimizer hyperparmeters\n",
        "args.lr = 1e-3\n",
        "args.optimizer ='Adam'\n",
        "args.lr_decay = 0.99\n",
        "args.decay_step = 1\n",
        "args.weight_decay =0\n",
        "\n",
        "# training hyperparameters\n",
        "args.batch_size = 32\n",
        "args.epochs = 300\n",
        "\n",
        "# others\n",
        "args.seed = 1\n",
        "\n",
        "args.work_dir = '/content/gdrive/My Drive/ma_proj/spiralnet_plus/reconstruction'\n",
        "args.data_fp = osp.join(args.work_dir, '..', 'data', args.dataset)\n",
        "args.out_dir = osp.join(args.work_dir, 'out', args.exp_name)\n",
        "args.checkpoints_dir = osp.join(args.out_dir, 'checkpoints')\n",
        "print(args)\n",
        "\n",
        "utils.makedirs(args.out_dir)\n",
        "utils.makedirs(args.checkpoints_dir)\n",
        "\n",
        "writer = writer.Writer(args)\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda', args.device_idx)\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "torch.set_num_threads(args.n_threads)\n",
        "\n",
        "# deterministic\n",
        "torch.manual_seed(args.seed)\n",
        "cudnn.benchmark = False\n",
        "cudnn.deterministic = True\n",
        "\n",
        "template_fp = osp.join(args.data_fp, 'template', 'template.obj')\n",
        "\n",
        "# generate/load transform matrices\n",
        "transform_fp = osp.join(args.data_fp, 'transform.pkl')\n",
        "print(template_fp)\n",
        "if not osp.exists(transform_fp):\n",
        "    print('Generating transform matrices...')\n",
        "    mesh = Mesh(filename=template_fp)\n",
        "    ds_factors = [4, 4, 4, 4]\n",
        "    _, _, D, U, F, V = mesh_sampling.generate_transform_matrices(\n",
        "        mesh, ds_factors)\n",
        "    tmp = {\n",
        "        'vertices': V,\n",
        "        'face': F, #'adj': A,\n",
        "        'down_transform': D,\n",
        "        'up_transform': U\n",
        "    }\n",
        "\n",
        "    with open(transform_fp, 'wb') as fp:\n",
        "        pickle.dump(tmp, fp)\n",
        "    print('Done!')\n",
        "    print('Transform matrices are saved in \\'{}\\''.format(transform_fp))\n",
        "else:\n",
        "    with open(transform_fp, 'rb') as f:\n",
        "        tmp = pickle.load(f, encoding='latin1')\n",
        "\n",
        "spiral_indices_list = [\n",
        "    utils.preprocess_spiral(tmp['face'][idx], args.seq_length[idx],\n",
        "                            tmp['vertices'][idx],\n",
        "                            args.dilation[idx]).to(device)\n",
        "    for idx in range(len(tmp['face']) - 1)\n",
        "]\n",
        "del tmp['face']\n",
        "del tmp['vertices']\n",
        "down_transform_list = [\n",
        "    utils.to_sparse(down_transform).to(device)\n",
        "    for down_transform in tmp['down_transform']\n",
        "]\n",
        "del tmp['down_transform']\n",
        "up_transform_list = [\n",
        "    utils.to_sparse(up_transform).to(device)\n",
        "    for up_transform in tmp['up_transform']\n",
        "]\n",
        "del tmp\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZvPOFsYDn8H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model = VAE(args.in_channels, args.out_channels, args.latent_channels,\n",
        "           spiral_indices_list, down_transform_list,\n",
        "           up_transform_list).to(device)\n",
        "del up_transform_list, down_transform_list, spiral_indices_list\n",
        "print('Number of parameters: {}'.format(utils.count_parameters(model)))\n",
        "print(model)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(),\n",
        "                             lr=args.lr,\n",
        "                             weight_decay=args.weight_decay)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
        "                                            args.decay_step,\n",
        "                                            gamma=args.lr_decay)\n",
        "\n",
        "# load dataset\n",
        "template_fp = osp.join(args.data_fp, 'template', 'template.obj')\n",
        "print('Creating MeshData obj')\n",
        "meshdata = MeshData(args.data_fp,\n",
        "                    template_fp,\n",
        "                    split=args.split,\n",
        "                    test_exp=args.test_exp)\n",
        "#print('creating training DataLoader')\n",
        "#train_loader = DataLoader(meshdata.train_dataset,\n",
        "#                          batch_size=args.batch_size,\n",
        "#                          shuffle=True)\n",
        "print('creating testing DataLoader')\n",
        "test_loader = DataLoader(meshdata.test_dataset, batch_size=args.batch_size)\n",
        "\n",
        "#run(model, train_loader, test_loader, args.epochs, optimizer, scheduler, writer, device)\n",
        "#print(model.en_mu.weight)\n",
        "#print(model.en_mu.weight)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6seLhMoNRHk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_state_dict(torch.load(osp.join(args.checkpoints_dir, 'checkpoint_300.pt'), map_location=torch.device('cpu'))['model_state_dict'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtWrhqYmNJdk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(meshdata.std)\n",
        "print(meshdata.mean)\n",
        "test_loss = test(model, test_loader, device)\n",
        "print(test_loss)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}