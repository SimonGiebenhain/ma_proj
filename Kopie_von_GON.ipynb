{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kopie von GON.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SimonGiebenhain/ma_proj/blob/master/Kopie_von_GON.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MK1Jl7nkLnPA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# requirements\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import numpy as np\n",
        "\n",
        "# colab requirements\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "from time import sleep"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bK383zeDM4Ac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# image data\n",
        "dataset_name = 'mnist' # ['mnist', 'fashion']\n",
        "img_size = 28\n",
        "n_channels = 1\n",
        "img_coords = 2\n",
        "\n",
        "# training info\n",
        "lr = 1e-4\n",
        "batch_size = 64\n",
        "num_latent = 10\n",
        "hidden_features = 128\n",
        "num_layers = 4\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_akWxzx0vhQK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create the GON network (a SIREN as in https://vsitzmann.github.io/siren/)\n",
        "class SirenLayer(nn.Module):\n",
        "    def __init__(self, in_f, out_f, w0=30, is_first=False, is_last=False):\n",
        "        super().__init__()\n",
        "        self.in_f = in_f\n",
        "        self.w0 = w0\n",
        "        self.linear = nn.Linear(in_f, out_f)\n",
        "        self.is_first = is_first\n",
        "        self.is_last = is_last\n",
        "        self.init_weights()\n",
        "    \n",
        "    def init_weights(self):\n",
        "        b = 1 / self.in_f if self.is_first else np.sqrt(6 / self.in_f) / self.w0\n",
        "        with torch.no_grad():\n",
        "            self.linear.weight.uniform_(-b, b)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        return x if self.is_last else torch.sin(self.w0 * x)\n",
        "\n",
        "class MLPLayer(nn.Module):\n",
        "    def __init__(self, in_f, out_f, is_last):\n",
        "        super().__init__()\n",
        "        self.in_f = in_f\n",
        "        self.is_last = is_last\n",
        "        self.linear = nn.Linear(in_f, out_f)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        return x if self.is_last else torch.nn.functional.relu(x)\n",
        "\n",
        "\n",
        "def gon_model(dimensions):\n",
        "    first_layer = SirenLayer(dimensions[0], dimensions[1], is_first=True)\n",
        "    other_layers = []\n",
        "    for dim0, dim1 in zip(dimensions[1:-2], dimensions[2:-1]):\n",
        "        other_layers.append(SirenLayer(dim0, dim1))\n",
        "    final_layer = SirenLayer(dimensions[-2], dimensions[-1], is_last=True)\n",
        "    return nn.Sequential(first_layer, *other_layers, final_layer)\n",
        "\n",
        "def simple_model(dimensions):\n",
        "    other_layers = []\n",
        "    for dim0, dim1 in zip(dimensions[0:-2], dimensions[1:-1]):\n",
        "        other_layers.append(MLPLayer(dim0, dim1, is_last=False))\n",
        "    final_layer = MLPLayer(dimensions[-2], dimensions[-1], is_last=True)\n",
        "    return nn.Sequential(*other_layers, final_layer)\n",
        "\n",
        "def ging_model(dimensions):\n",
        "    first_layer = SirenLayer(dimensions[0], dimensions[1], is_first=True)\n",
        "    other_layers_trainee = []\n",
        "    for dim0, dim1 in zip(dimensions[1:-2], dimensions[2:-1]):\n",
        "        other_layers_trainee.append(SirenLayer(dim0, dim1))\n",
        "    other_layers_trainer = []\n",
        "    for dim0, dim1 in zip(dimensions[1:-2], dimensions[2:-1]):\n",
        "        other_layers_trainer.append(SirenLayer(dim0, dim1))\n",
        "    final_layer_trainee = SirenLayer(dimensions[-2], dimensions[-1], is_last=True)\n",
        "    final_layer_trainer = SirenLayer(dimensions[-2], 6, is_last=True)\n",
        "    return nn.Sequential(first_layer, *other_layers_trainee, final_layer_trainee), nn.Sequential(first_layer, *other_layers_trainer, final_layer_trainer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSdL9Ql_v1PB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###### helper functions #####\n",
        "def get_mgrid(sidelen, dim=2):\n",
        "    tensors = tuple(dim * [torch.linspace(-1, 1, steps=sidelen)])\n",
        "    mgrid = torch.stack(torch.meshgrid(*tensors), dim=-1)\n",
        "    mgrid = mgrid.reshape(-1, dim)\n",
        "    return mgrid\n",
        "\n",
        "def cycle(iterable):\n",
        "    while True:\n",
        "        for x in iterable:\n",
        "            yield x\n",
        "\n",
        "def slerp(a, b, t):\n",
        "    omega = torch.acos((a/torch.norm(a, dim=1, keepdim=True)*b/torch.norm(b, dim=1, keepdim=True)).sum(1)).unsqueeze(1)\n",
        "    res = (torch.sin((1.0-t)*omega)/torch.sin(omega))*a + (torch.sin(t*omega)/torch.sin(omega)) * b\n",
        "    return res\n",
        "\n",
        "def slerp_batch(model, z, coords):\n",
        "    lz = z.data.clone().squeeze(1)\n",
        "    col_size = int(np.sqrt(z.size(0)))\n",
        "    src_z = lz.data[:col_size].repeat(col_size,1)\n",
        "    z1, z2 = lz.data.split(lz.shape[0]//2)\n",
        "    tgt_z = torch.cat([z2, z1])\n",
        "    tgt_z = tgt_z[:col_size].repeat(col_size,1)\n",
        "    t = torch.linspace(0,1,col_size).unsqueeze(1).repeat(1,col_size).contiguous().view(batch_size,1).contiguous().to(device)\n",
        "    z_slerp = slerp(src_z, tgt_z, t)\n",
        "    z_slerp_rep = z_slerp.unsqueeze(1).repeat(1,coords.size(1),1) \n",
        "    g_slerp = model(torch.cat((coords, z_slerp_rep), dim=-1))\n",
        "    return g_slerp\n",
        "\n",
        "def gon_sample(model, recent_zs, coords):\n",
        "    zs = torch.cat(recent_zs, dim=0).squeeze(1).cpu().numpy()\n",
        "    mean = np.mean(zs, axis=0)\n",
        "    cov = np.cov(zs.T)\n",
        "    sample = np.random.multivariate_normal(mean, cov, size=batch_size)\n",
        "    sample = torch.tensor(sample).unsqueeze(1).repeat(1,coords.size(1),1).to(device).float()\n",
        "    model_input = torch.cat((coords, sample), dim=-1)\n",
        "    return model(model_input)\n",
        "\n",
        "# This function returns the indices of bounding boxes of radius 'radius' around \n",
        "# the sampled locations 'loc_samps'.\n",
        "# @Arguments:\n",
        "#   - loc_samps: tensor of dimensions [batch_size, sample_size, dim]\n",
        "#   - radius: radius of window around sampled location\n",
        "#   - img_size: size of complete image\n",
        "# @Returns:\n",
        "#   - windos: window indices of dimensions [batch_size, sample_size, (2*radius+1)^dim, dim], \n",
        "#   where the size of the second to last dimension might be smaller, if the window\n",
        "#   would reach outside of the image otherwise.\n",
        "#   - ds: distances of sampled location to every point in the window\n",
        "def get_windows(loc_samps, radius, img_size, smoothness):\n",
        "  batch_size = loc_samps.shape[0]\n",
        "  sample_size = loc_samps.shape[1]\n",
        "  dims = loc_samps.shape[2]\n",
        "\n",
        "  #compute indices\n",
        "  scaled_samps = (loc_samps+1)/2*(img_size-1)\n",
        "  centers = torch.round(scaled_samps).long()\n",
        "  grid_x, grid_y = torch.meshgrid(torch.arange(-radius, radius+1, device=device, dtype=torch.long), torch.arange(-radius, radius+1, device=device, dtype=torch.long))\n",
        "  grid = torch.stack([grid_x, grid_y], dim=2)\n",
        "  windows = grid.view(1, 1, -1, dims) + centers.view(batch_size, sample_size, 1, dims)\n",
        "  valid_locs = torch.logical_and(windows <= img_size - 1, windows >= 0)\n",
        "  \n",
        "  #compute distances\n",
        "  ds = torch.sqrt(torch.sum((scaled_samps.view(batch_size, sample_size, 1, dims) - windows)**2, dim=3))\n",
        "\n",
        "  \n",
        "\n",
        "  #compute weights\n",
        "  w = torch.where(valid_locs.all(3), torch.softmax(-smoothness*ds, dim=2), torch.zeros(1, device=device))  \n",
        "    # investigated softmin temperature, 5 seems to be good\n",
        "    #topw, _ = torch.topk(ds, 5, dim=2)\n",
        "    #topd, _ = torch.topk(ds, 5, dim=2, largest=False)\n",
        "    #print('distances')\n",
        "    #print(topd[:3, :3, :])\n",
        "    #print('weights')\n",
        "    #print(topw[:3, :3, :])\n",
        "  #w = torch.zeros([batch_size, sample_size, windows.shape[2]]).to(device)\n",
        "  #w[valid_locs.all(3)] = \n",
        "  ##invalid locations get wieght 0\n",
        "  #w[(~valid_locs).any(3)] = 0\n",
        "\n",
        "  #invalid locations get assigned index 0 in order to prevent indexing error\n",
        "  windows[~valid_locs] = 0\n",
        "\n",
        "  return windows, w\n",
        "\n",
        "def linearize_idx(idx, img_size):\n",
        "  dims = idx.shape[-1]\n",
        "  lin_idx = torch.zeros(idx.shape[:-1], dtype=torch.long).to(device)\n",
        "  for d in range(dims):\n",
        "    lin_idx += idx[:, :, :, d] * img_size**(dims-1-d)\n",
        "  return lin_idx\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "class IdxedDataset(Dataset):\n",
        "    def __init__(self, dataset):\n",
        "        self.dataset = dataset\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        data, target = self.dataset[index]    \n",
        "        return data, target, index\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWsh5VddjMqm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TEST: linearize_idx()\n",
        "#xx, yy, zz = torch.meshgrid(torch.arange(2), torch.arange(2), torch.arange(2))\n",
        "#print(xx)\n",
        "#idx = torch.stack([xx, yy, zz], dim=3)\n",
        "#print(idx)\n",
        "#print(idx.shape)\n",
        "#I = torch.arange(8).view(2,2,2)\n",
        "#print(I)\n",
        "#print(I.view(-1))\n",
        "#idx = idx.view(8,3)\n",
        "#print(idx)\n",
        "##print(idx[:, 0]*3**0)\n",
        "##print(idx[:, 1]*3**1)\n",
        "##print(idx[:, 0]*3**0 + idx[:, 1]*3**1)\n",
        "#linearize_idx(idx.view(1, 1, 8, 3), 2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPIGu4gev9gz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### load datasets #####\n",
        "if dataset_name == 'mnist':\n",
        "    dataset_train = torchvision.datasets.MNIST('data', train=True, download=True, transform=torchvision.transforms.Compose([\n",
        "        torchvision.transforms.ToTensor()\n",
        "    ]))\n",
        "    dataset_test = torchvision.datasets.MNIST('data', train=False, download=True, transform=torchvision.transforms.Compose([\n",
        "        torchvision.transforms.ToTensor()\n",
        "    ]))\n",
        "if dataset_name == 'fashion':\n",
        "    dataset_train = torchvision.datasets.FashionMNIST('data', train=True, download=True, transform=torchvision.transforms.Compose([\n",
        "        torchvision.transforms.ToTensor()\n",
        "    ]))\n",
        "    dataset_test = torchvision.datasets.FashionMNIST('data', train=False, download=True, transform=torchvision.transforms.Compose([\n",
        "        torchvision.transforms.ToTensor()\n",
        "    ]))\n",
        "print(dataset_train)\n",
        "print(dataset_test)\n",
        "dataset_train = IdxedDataset(dataset_train)\n",
        "dataset_test = IdxedDataset(dataset_test)\n",
        "#loader = DataLoader(dataset,\n",
        "#                    batch_size=1,\n",
        "#                    shuffle=True,\n",
        "#                    num_workers=1)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset_train, sampler=None, shuffle=True, batch_size=batch_size, drop_last=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset_test, sampler=None, shuffle=True, batch_size=batch_size, drop_last=True)\n",
        "\n",
        "train_iterator = iter(cycle(train_loader))\n",
        "test_iterator = iter(cycle(test_loader))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEXIxrTswSvE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### SETUP MODEL #####\n",
        "\n",
        "# define GON architecture, for example gon_shape = [34, 256, 256, 256, 256, 1]\n",
        "gon_shape = [img_coords+num_latent] + [hidden_features]*num_layers + [n_channels]\n",
        "    #num_noise = 2\n",
        "    #adv_shape = [num_latent] + [hidden_features]*3 + [img_coords]\n",
        "F = gon_model(gon_shape).to(device)\n",
        "    #adv = gon_model(adv_shape).to(device)\n",
        "\n",
        "optim_main = torch.optim.Adam(lr=lr, params=F.parameters())\n",
        "    #optim_main_fine = torch.optim.Adam(lr=lr, params=F.parameters())\n",
        "    #optim_adv = torch.optim.Adam(lr=lr, params=adv.parameters())\n",
        "\n",
        "c = torch.stack([get_mgrid(img_size, 2) for _ in range(batch_size)]).to(device) # coordinates\n",
        "\n",
        "recent_zs = []\n",
        "print(f'> Number of parameters {len(torch.nn.utils.parameters_to_vector(F.parameters()))}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyV20KlQuAGJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### TRAINING #####\n",
        "\n",
        "#z = torch.randn(dataset.__len__(), num_latent).to(device) #torch.zeros(dataset.__len__(), num_latent).to(device)\n",
        "#z.requires_grad_(True)\n",
        "#optim_latent = torch.optim.Adam(params=[z], lr=1e-3)\n",
        "#for ep in range(50):\n",
        "#  print('EPOCH: {}'.format(ep))\n",
        "#  for step, (x, t, idx) in enumerate(train_loader):\n",
        "for step in range(501):\n",
        "    # sample a batch of data\n",
        "    x, t, idx = next(train_iterator)\n",
        "    x, t, idx = x.to(device), t.to(device), idx.to(device)\n",
        "    x = x.permute(0, 2, 3, 1)\n",
        "    x = x.reshape(batch_size, -1, n_channels)\n",
        "    z = torch.zeros(batch_size, 1, num_latent).to(device).requires_grad_()\n",
        "    z_rep_main = z.repeat(1,c.size(1),1)\n",
        "    g = F(torch.cat((c, z_rep_main), dim=-1))\n",
        "    L_inner = ((g - x)**2).sum(1).mean()\n",
        "    z_main = -torch.autograd.grad(L_inner, [z], create_graph=True, retain_graph=True)[0]\n",
        "    z_rep_main = z_main.repeat(1, c.size(1), 1)\n",
        "    #z_rep = z[idx, :]\n",
        "    #z_main = z_rep.unsqueeze(1)\n",
        "    #z_rep_main = z_main.repeat(1, c.size(1), 1)\n",
        "    \n",
        "    \n",
        "    \n",
        "    #z_rep_adv = z_main.repeat(1, sample_size, 1).detach().clone()\n",
        "\n",
        "    #g = F(torch.cat((c, z_rep_main), dim=-1))\n",
        "    #L_outer = ((g - x)**2).sum(1).mean()\n",
        "    #print('normal loss:{}'.format(L_outer.data))\n",
        "    #optim_main.zero_grad()\n",
        "    #L_outer.backward()\n",
        "    #optim_main.step()\n",
        "\n",
        "\n",
        "    #noise = torch.from_numpy(np.random.normal(0, 1, [batch_size, sample_size, num_noise])).float().to(device)\n",
        "    #samps = torch.sigmoid(adv(torch.cat([noise, z_rep_adv], dim=-1)))\n",
        "    #samps_discr = torch.round(samps * img_size).long()\n",
        "    #samps_discr = samps_discr[:, :, 0]*img_size + samps_discr[:, :, 1]\n",
        "    #if step % 10 == 0:\n",
        "    #  print(samps_discr)\n",
        "\n",
        "    # now with z as our new latent points, optimise the data fitting loss\n",
        "    g = F(torch.cat((c, z_rep_main), dim=-1))\n",
        "    L_outer = ((g - x)**2).sum(1).mean()\n",
        "    #L_outer = ((g - x[torch.arange(batch_size).unsqueeze(1), samps_discr, :])**2).mean(1).mean()\n",
        "    if step % 20 == 0:\n",
        "      print('sampled loss:{}'.format(L_outer.data))\n",
        "    #optim_adv.zero_grad()\n",
        "    optim_main.zero_grad()\n",
        "    #optim_latent.zero_grad()\n",
        "    L_outer.backward()\n",
        "    #for p in adv.parameters():\n",
        "    #  if p.grad is not None: \n",
        "    #   p.grad.data.mul_(-1) \n",
        "    #optim_adv.step()\n",
        "    optim_main.step()\n",
        "    #optim_latent.step()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # compute sampling statistics\n",
        "    recent_zs.append(z_main.detach())\n",
        "    recent_zs = recent_zs[-100:]\n",
        "\n",
        "    if step % 100 == 0 and step > 0:\n",
        "        print(f\"Step: {step}   Loss: {L_outer.item():.3f}\")\n",
        "        z_rep = z_main.repeat(1, c.shape[1], 1)\n",
        "        g = F(torch.cat((c, z_rep), dim=-1))\n",
        "        # plot reconstructions, interpolations, and samples\n",
        "        recons = torchvision.utils.make_grid(torch.clamp(g, 0, 1).permute(0,2,1).reshape(-1, n_channels, img_size, img_size), nrow=8)\n",
        "        slerps = torchvision.utils.make_grid(torch.clamp(slerp_batch(F, z_main.data, c), 0, 1).permute(0,2,1).reshape(-1, n_channels, img_size, img_size), nrow=8)\n",
        "        sample = torchvision.utils.make_grid(torch.clamp(gon_sample(F, recent_zs, c), 0, 1).permute(0,2,1).reshape(-1, n_channels, img_size, img_size))\n",
        "\n",
        "        plt.title('Reconstructions')\n",
        "        plt.imshow(recons[0,:,:].reshape(242,242,1).repeat(1,1,3).cpu().data.numpy())\n",
        "        plt.figure()\n",
        "        plt.title('Spherical Interpolations')\n",
        "        plt.imshow(slerps[0,:,:].reshape(242,242,1).repeat(1,1,3).cpu().data.numpy())\n",
        "        plt.figure()\n",
        "        plt.title('Samples')\n",
        "        plt.imshow(sample[0,:,:].reshape(242,242,1).repeat(1,1,3).cpu().data.numpy())\n",
        "        plt.show()\n",
        "        sleep(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teSzVCQMUCDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### TESTING #####\n",
        "\n",
        "recent_zs_test = []\n",
        "cum_loss_test = 0\n",
        "num_batches_test = 0\n",
        "\n",
        "for step, (x, t, idx) in enumerate(test_loader):\n",
        "    x, t, idx = x.to(device), t.to(device), idx.to(device)\n",
        "    x = x.permute(0, 2, 3, 1)\n",
        "    x = x.reshape(batch_size, -1, n_channels)\n",
        "    z = torch.zeros(batch_size, 1, num_latent).to(device).requires_grad_()\n",
        "    z_rep_main = z.repeat(1,c.size(1),1)\n",
        "    g = F(torch.cat((c, z_rep_main), dim=-1))\n",
        "    L_inner = ((g - x)**2).sum(1).mean()\n",
        "    z_main = -torch.autograd.grad(L_inner, [z], create_graph=True, retain_graph=False)[0]\n",
        "    z_rep_main = z_main.repeat(1, c.size(1), 1)\n",
        "\n",
        "    # now with z as our new latent points, optimise the data fitting loss\n",
        "    g = F(torch.cat((c, z_rep_main), dim=-1))\n",
        "    cum_loss_test += ((g - x)**2).sum(1).mean().item()\n",
        "    num_batches_test += 1\n",
        "    # compute sampling statistics\n",
        "    recent_zs_test.append(z_main.detach())\n",
        "    recent_zs_test = recent_zs_test[-100:]\n",
        "\n",
        "\n",
        "avg_loss_test = cum_loss_test / num_batches_test\n",
        "print('Average test loss: {}'.format(avg_loss_test))\n",
        "\n",
        "z_rep = z_main.repeat(1, c.shape[1], 1)\n",
        "g = F(torch.cat((c, z_rep), dim=-1))\n",
        "# plot reconstructions, interpolations, and samples\n",
        "recons = torchvision.utils.make_grid(torch.clamp(g, 0, 1).permute(0,2,1).reshape(-1, n_channels, img_size, img_size), nrow=8)\n",
        "slerps = torchvision.utils.make_grid(torch.clamp(slerp_batch(F, z_main.data, c), 0, 1).permute(0,2,1).reshape(-1, n_channels, img_size, img_size), nrow=8)\n",
        "sample = torchvision.utils.make_grid(torch.clamp(gon_sample(F, recent_zs, c), 0, 1).permute(0,2,1).reshape(-1, n_channels, img_size, img_size))\n",
        "\n",
        "plt.title('Reconstructions')\n",
        "plt.imshow(recons[0,:,:].reshape(242,242,1).repeat(1,1,3).cpu().data.numpy())\n",
        "plt.figure()\n",
        "plt.title('Spherical Interpolations')\n",
        "plt.imshow(slerps[0,:,:].reshape(242,242,1).repeat(1,1,3).cpu().data.numpy())\n",
        "plt.figure()\n",
        "plt.title('Samples')\n",
        "plt.imshow(sample[0,:,:].reshape(242,242,1).repeat(1,1,3).cpu().data.numpy())\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51Ww6JNND6dE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_latent_adv = 3\n",
        "num_noise = 10\n",
        "\n",
        "adv_shape = [num_latent + num_noise] + [128]*4 + [img_coords]\n",
        "adv = simple_model(adv_shape).to(device)\n",
        "optim_adv = torch.optim.Adam(lr=1e-3, params=adv.parameters())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3YZXEHD0m2Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_size = 300\n",
        "#batch_size = 64\n",
        "#c = torch.stack([get_mgrid(img_size, 2) for _ in range(batch_size)]).to(device) # coordinates\n",
        "#train_loader = torch.utils.data.DataLoader(dataset_train, sampler=None, shuffle=True, batch_size=batch_size, drop_last=True)\n",
        "#test_loader = torch.utils.data.DataLoader(dataset_test, sampler=None, shuffle=True, batch_size=batch_size, drop_last=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGxnxEMWlHl4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "direct_idx = torch.zeros(batch_size, sample_size, 2).to(device)#torch.FloatTensor(batch_size, sample_size, 2).uniform_(-1, 1).to(device)#\n",
        "direct_idx.requires_grad_(True)\n",
        "optim_direct = torch.optim.Adam([direct_idx], lr=1e-3)\n",
        "#ZADV = torch.zeros(batch_size, sample_size, num_latent_adv).to(device)\n",
        "#ZADV.requires_grad_(True)\n",
        "#optim_latent = torch.optim.Adam([ZADV], lr= 1e-4)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6PSX9CNsOae",
        "colab_type": "text"
      },
      "source": [
        "# TODO\n",
        "- check if boundary cases work with entropy as well\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeZ7DhZqWF7c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm.notebook import trange\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "OPT_STEPS = 0\n",
        "N_EPOCHS = 10\n",
        "locs = np.zeros([N_EPOCHS, batch_size, sample_size, 2])\n",
        "F.eval()\n",
        "recent_samples_x = np.zeros([250000])\n",
        "recent_samples_y = np.zeros([250000])\n",
        "heatmap_history = []\n",
        "count = 0\n",
        "\n",
        "names = [\"Epoch\", \"SamplingLoss\", \"Entropy\"]\n",
        "layout = \"{!s:15} \" * len(names)\n",
        "\n",
        "def print_stats(epoch, values, decimals=6):\n",
        "    layout = \"{!s:^15}\" + \" {!s:15}\" * len(values)\n",
        "    values = [epoch] + list(np.round(values, decimals))\n",
        "    print(layout.format(*values))\n",
        "\n",
        "for epoch in trange(N_EPOCHS, desc='Epoch'):\n",
        "  sampling_loss_train = 0\n",
        "  #MSGAN_loss_train = 0\n",
        "  entropy_train = 0\n",
        "\n",
        "  tq = tqdm(iter(train_loader), leave=False, total=len(train_loader), position=0)\n",
        "  for i, (x, t, idx) in enumerate(tq):\n",
        "    x, t = x.to(device), t.to(device)\n",
        "    x = x.permute(0, 2, 3, 1)\n",
        "    x = x.reshape(batch_size, -1, n_channels)\n",
        "\n",
        "    z = torch.zeros(batch_size, 1, num_latent).to(device).requires_grad_()\n",
        "    z_rep_main = z.repeat(1,c.size(1),1)\n",
        "    g = F(torch.cat((c, z_rep_main), dim=-1))\n",
        "    L_inner = ((g - x)**2).sum(1).mean()\n",
        "    z_main = -torch.autograd.grad(L_inner, [z], create_graph=True, retain_graph=True)[0]\n",
        "    z_rep_main = z_main.repeat(1, sample_size, 1)\n",
        "\n",
        "    #z = torch.zeros(batch_size, 1, num_latent).to(device).requires_grad_()\n",
        "    #z_adv = z.repeat(1, sample_size, 1)\n",
        "    #samps_inner = torch.tanh(adv(z_adv))\n",
        "    #samps_discr_inner = torch.floor((samps_inner+1)/2 * img_size).long().detach()\n",
        "    #samps_discr_inner = samps_discr_inner[:, :, 0]*img_size + samps_discr_inner[:, :, 1]\n",
        "    #g = F(torch.cat((samps_inner, z_rep_main), dim=-1))\n",
        "    #L_adv_inner = ((g - x[torch.arange(batch_size).unsqueeze(1), samps_discr_inner, :])**2).sum(1).mean()\n",
        "    #z_adv = -torch.autograd.grad(L_adv_inner, [z], create_graph=True, retain_graph=True)[0]\n",
        "    #z_rep_adv = z_adv.repeat(1, sample_size, 1)\n",
        "    #z_rep_adv = ZADV.repeat(1, sample_size, 1)\n",
        "\n",
        "    #g = F(torch.cat((c, z_rep_main), dim=-1))\n",
        "    #L_outer = ((g - x)**2).sum(1).mean()\n",
        "    #print('normal loss:{}'.format(L_outer.data))\n",
        "    #optim_main.zero_grad()\n",
        "    #L_outer.backward()\n",
        "    #optim_main.step()\n",
        "\n",
        "\n",
        "    noise1 = torch.from_numpy(np.random.normal(0, 1, [batch_size, sample_size, num_noise])).float().to(device)\n",
        "    #noise2 = torch.from_numpy(np.random.normal(0, 1, [batch_size, sample_size, num_noise])).float().to(device)\n",
        "\n",
        "    samps1 = torch.tanh(adv(torch.cat([noise1, z_rep_main.detach()], dim=2)))\n",
        "    #samps2 = torch.tanh(adv(torch.cat([noise2, z_rep_main.detach()], dim=2)))\n",
        "\n",
        "    lin_samps = samps1.view(-1, 2)\n",
        "    n_samps = lin_samps.shape[0] \n",
        "    if count + n_samps > recent_samples_x.shape[0]:\n",
        "      overflow = count + n_samps - recent_samples_x.shape[0]\n",
        "      recent_samples_x[count:] = lin_samps[:n_samps - overflow, 0].detach().cpu().data.numpy()\n",
        "      recent_samples_y[count:] = lin_samps[:n_samps - overflow, 1].detach().cpu().data.numpy()\n",
        "      recent_samples_x[: overflow] = lin_samps[-overflow:, 0].detach().cpu().data.numpy()\n",
        "      recent_samples_y[: overflow] = lin_samps[-overflow:, 1].detach().cpu().data.numpy()\n",
        "      count = overflow\n",
        "      heatmap, _, _ = np.histogram2d(recent_samples_x, recent_samples_y, bins=(28, 28), range=[[-1, 1], [-1, 1]])\n",
        "      heatmap_history.append(heatmap)\n",
        "    else:\n",
        "      recent_samples_x[count: count + n_samps] = lin_samps[:, 0].detach().cpu().data.numpy()\n",
        "      recent_samples_y[count: count + n_samps] = lin_samps[:, 1].detach().cpu().data.numpy()\n",
        "      count = count + n_samps\n",
        "\n",
        "    #samps1 = torch.tanh(adv(z_rep_main))\n",
        "\n",
        "    #samps1 = torch.FloatTensor(batch_size, sample_size,2).uniform_(-1, 1).to(device) #direct_idx\n",
        "    #samps1 = direct_idx\n",
        "    if i == 0:\n",
        "      locs[epoch, :, :, :] = samps1.detach().cpu().data\n",
        "\n",
        "\n",
        "    windows1, w1 = get_windows(samps1, radius=1, img_size=img_size, smoothness=5)\n",
        "    #windows2, w2 = get_windows(samps2, radius=1, img_size=img_size, smoothness=5)\n",
        "\n",
        "\n",
        "    # linearize window index, should have shape [batch_size x sample_size * window_size]\n",
        "    win_lin1 = linearize_idx(windows1, img_size).view(batch_size, -1)\n",
        "    x_cropped1 = x[torch.arange(batch_size).unsqueeze(1), win_lin1, :].view(batch_size, sample_size, -1) #window_size\n",
        "    target1 = torch.matmul(w1.view(batch_size, sample_size, 1, -1), x_cropped1.view(batch_size, sample_size, -1, 1))\n",
        "\n",
        "    #win_lin2 = linearize_idx(windows2, img_size).view(batch_size, -1)\n",
        "    #x_cropped2 = x[torch.arange(batch_size).unsqueeze(1), win_lin2, :].view(batch_size, sample_size, -1)\n",
        "    #target2 = torch.matmul(w2.view(batch_size, sample_size, 1, -1), x_cropped2.view(batch_size, sample_size, -1, 1))\n",
        "\n",
        "    #ds = torch.sqrt(((c - samps1.repeat(1, 784, 1))**2).sum(2))\n",
        "    #w = torch.softmax(-50*ds, dim=1)\n",
        "    #print(torch.topk(w[:5, :5, :], 5, dim=2))\n",
        "        \n",
        "\n",
        "    #target = torch.bmm(w.view(batch_size, 1, 784), x.view(batch_size, 784, 1))\n",
        "\n",
        "\n",
        "\n",
        "    mesh_size = 3\n",
        "    #TODO get x and y range for the meshgrid: what to do for boundary cases\n",
        "    # produce meshgrid, stack meshes, get distances, weights and targets as before\n",
        "    \n",
        "    #samps_ceil = torch.ceil(((samps1.clamp(-1,1)+1)/2)*(img_size-1)).detach()\n",
        "    #samps_floor = torch.floor(((samps1.clamp(-1,1)+1)/2)*(img_size-1)).detach()\n",
        "    #xl = samps_floor[:, :, 0]\n",
        "    #xu = samps_ceil[:, :, 0]\n",
        "    #yl = samps_floor[:, :, 1]\n",
        "    #yu = samps_ceil[:, :, 1]\n",
        "\n",
        "    #p1 = torch.stack([xl, yl], 2)\n",
        "    #p2 = torch.stack([xu, yl], 2)\n",
        "    #p3 = torch.stack([xl, yu], 2)\n",
        "    #p4 = torch.stack([xu, yu], 2)\n",
        "    #w1 = torch.sqrt(((samps1 - p1)**2).sum(2)).requires_grad_(True)\n",
        "    #w2 = torch.sqrt(((samps1 - p2)**2).sum(2)).requires_grad_(True)\n",
        "    #w3 = torch.sqrt(((samps1 - p3)**2).sum(2)).requires_grad_(True)\n",
        "    #w4 = torch.sqrt(((samps1 - p4)**2).sum(2)).requires_grad_(True)\n",
        "    #w = torch.stack([w1, w2, w3, w4], dim=2)\n",
        "    #w = w / torch.sum(w, dim=2).unsqueeze(2)\n",
        "       #w = torch.softmax(w, dim=2)\n",
        "    #p1_idx = p1[:, :, 0] * img_size + p1[:, :, 1]\n",
        "    #p2_idx = p2[:, :, 0] * img_size + p2[:, :, 1]\n",
        "    #p3_idx = p3[:, :, 0] * img_size + p3[:, :, 1]\n",
        "    #p4_idx = p4[:, :, 0] * img_size + p4[:, :, 1]\n",
        "    #target = w[:, :, 0].unsqueeze(2) * x[torch.arange(batch_size).unsqueeze(1), p1_idx.long(), :] + \\\n",
        "    #         w[:, :, 1].unsqueeze(2) * x[torch.arange(batch_size).unsqueeze(1), p2_idx.long(), :] + \\\n",
        "    #         w[:, :, 2].unsqueeze(2) * x[torch.arange(batch_size).unsqueeze(1), p3_idx.long(), :] + \\\n",
        "    #         w[:, :, 3].unsqueeze(2) * x[torch.arange(batch_size).unsqueeze(1), p4_idx.long(), :]\n",
        "            \n",
        "\n",
        "\n",
        "\n",
        "    #noise2 = torch.from_numpy(np.random.normal(0, 1, [batch_size, sample_size, num_noise])).float().to(device)\n",
        "    #samps2 = torch.tanh(adv(torch.cat([noise2, z_rep_adv], dim=-1)))\n",
        "    #samps2 = torch.FloatTensor(1,1,2).uniform_(-1, 1).to(device)\n",
        "    #samps2 = samps2.repeat(samps1.shape[0], samps1.shape[1], 1)\n",
        "\n",
        "\n",
        "    #samps_discr1 = samps_discr1[:, :, 0]*img_size + samps_discr1[:, :, 1]\n",
        "    #samps_discr2 = torch.floor((samps2+1)/2 * img_size).long().detach()\n",
        "    #samps_discr2 = samps_discr2[:, :, 0] * img_size + samps_discr2[:, :, 1]\n",
        "    \n",
        "    #samps = torch.cat([samps1, samps2], 1)\n",
        "    #samps_discr = torch.cat([samps_discr1, samps_discr2], 1)\n",
        "    #if step % 20 == 0:\n",
        "    #  print(samps_discr1)\n",
        "\n",
        "    #print(noise1)\n",
        "    #print(noise2)\n",
        "\n",
        "    #### ENFORCING DIVERSITY ####\n",
        "    #lz = ((torch.abs(samps1 - samps2)).sum(2) / (\n",
        "    #        torch.abs(noise1 - noise2)).sum(2)).sum(1).mean()\n",
        "    \n",
        "    #lz = 1 / (lz/1000 + 1e-12)\n",
        "\n",
        "    # TODO abstruct '2' to 'dims'\n",
        "    counts_decompressed1 = torch.zeros([batch_size, sample_size, img_size**2]).to(device)\n",
        "    counts_decompressed1[torch.arange(batch_size).unsqueeze(1).unsqueeze(2), torch.arange(sample_size).unsqueeze(0).unsqueeze(2), win_lin1.view(batch_size, sample_size, -1)] = w1\n",
        "    counts1 = (counts_decompressed1.sum(1))/(sample_size)\n",
        "    entropy1 = -torch.sum(torch.log1p(counts1), dim=1).mean()\n",
        "\n",
        "    #counts_decompressed2 = torch.zeros([batch_size, sample_size, img_size**2]).to(device)\n",
        "    #counts_decompressed2[torch.arange(batch_size).unsqueeze(1).unsqueeze(2), torch.arange(sample_size).unsqueeze(0).unsqueeze(2), win_lin2.view(batch_size, sample_size, -1)] = w2\n",
        "    #counts2 = (counts_decompressed2.sum(1))/(sample_size)\n",
        "    #entropy2 = -torch.sum(torch.log1p(counts2), dim=1).mean()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #### OPTIMIZATION ####\n",
        "    # now with z as our new latent points, optimise the data fitting loss\n",
        "    g1 = F(torch.cat((samps1, z_rep_main.detach()), dim=-1))\n",
        "    #g2 = F(torch.cat((samps2, z_rep_main.detach()), dim=-1))\n",
        "\n",
        "    #L_outer = -((g - x[torch.arange(batch_size).unsqueeze(1), samps_discr1, :])**2).sum(1).mean() #- 3*lz\n",
        "    L_outer1 = -((g1.squeeze() - target1.squeeze()).abs().mean(1).mean()) \n",
        "    #L_outer2 = -((g2.squeeze() - target2.squeeze()).abs().mean(1).mean())\n",
        "\n",
        "\n",
        "    #if i % 20 == 0:\n",
        "    #  print('sampled loss:{}'.format(L_outer1.item()))\n",
        "    #  print('diversity loss (ModeSeekingGAN):{}'.format(lz.item()))\n",
        "    L_outer = L_outer1#(L_outer1 + L_outer2) / 2\n",
        "    entropy = entropy1#(entropy1+ entropy2) / 2\n",
        "    L_total = L_outer + 7.5*entropy  #+0.005*lz\n",
        "    sampling_loss_train += L_outer.item()\n",
        "    #MSGAN_loss_train += lz.item()\n",
        "    entropy_train += entropy.item()\n",
        "    tq.set_postfix(loss=L_outer.item(), MSGAN_loss=lz.item(), entropy=entropy.item())\n",
        "\n",
        "    #L_outer -= 0.4*( torch.var(samps1[:, :, 0]) + torch.var(samps1[:, :, 1]) )\n",
        "    optim_adv.zero_grad()\n",
        "    #optim_latent.zero_grad()\n",
        "    #optim_main_fine.zero_grad()\n",
        "    #optim_direct.zero_grad()\n",
        "    L_total.backward()\n",
        "\n",
        "    #for p in adv.parameters():\n",
        "    #  if p.grad is not None: \n",
        "    #   p.grad.data.mul_(-1) \n",
        "    #torch.nn.utils.clip_grad_norm_(adv.parameters(), 0.01)\n",
        "    #torch.nn.utils.clip_grad_norm_(direct_idx, 0.1)\n",
        "    optim_adv.step()\n",
        "    #optim_latent.step()\n",
        "    #optim_main_fine.step()\n",
        "    #optim_direct.step()\n",
        "    #g = F(torch.cat((samps2, z_rep_main), dim=-1))\n",
        "    #L_outer = ((g - x[torch.arange(batch_size).unsqueeze(1), samps_discr2, :])**2).sum(1).mean() #- 3*lz\n",
        "    #if step % 20 == 0:\n",
        "    #print('random loss:{}'.format(L_outer.item()))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    ## compute sampling statistics\n",
        "    #recent_zs.append(z_main.detach())\n",
        "    #recent_zs = recent_zs[-100:]\n",
        "\n",
        "    #if step % 100 == 0 and step > 0:\n",
        "    #    z_rep = z_main.repeat(1, c.shape[1], 1)\n",
        "    #    g = F(torch.cat((c, z_rep), dim=-1))\n",
        "    #    # plot reconstructions, interpolations, and samples\n",
        "    #    recons = torchvision.utils.make_grid(torch.clamp(g, 0, 1).permute(0,2,1).reshape(-1, n_channels, img_size, img_size), nrow=8)\n",
        "    #    slerps = torchvision.utils.make_grid(torch.clamp(slerp_batch(F, z_main.data, c), 0, 1).permute(0,2,1).reshape(-1, n_channels, img_size, img_size), nrow=8)\n",
        "    #    sample = torchvision.utils.make_grid(torch.clamp(gon_sample(F, recent_zs, c), 0, 1).permute(0,2,1).reshape(-1, n_channels, img_size, img_size))\n",
        "\n",
        "    #    plt.title('Reconstructions')\n",
        "    #    plt.imshow(recons[0,:,:].reshape(242,242,1).repeat(1,1,3).cpu().data.numpy())\n",
        "    #    plt.figure()\n",
        "    #    plt.title('Spherical Interpolations')\n",
        "    #    plt.imshow(slerps[0,:,:].reshape(242,242,1).repeat(1,1,3).cpu().data.numpy())\n",
        "    #    plt.figure()\n",
        "    #    plt.title('Samples')\n",
        "    #    plt.imshow(sample[0,:,:].reshape(242,242,1).repeat(1,1,3).cpu().data.numpy())\n",
        "    #    plt.show()\n",
        "    #    sleep(1)\n",
        "  \n",
        "  if epoch == 0:\n",
        "        print(f\"\\n{layout.format(*names)}\")\n",
        "  print_stats(epoch, [sampling_loss_train / len(train_loader), entropy_train / len(train_loader)])\n",
        "  plt.figure(figsize=(2, 2))\n",
        "  plt.imshow(heatmap)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "heatmap, xedges, yedges = np.histogram2d(recent_samples_x, recent_samples_y, bins=(28, 28), range=[[-1, 1], [-1, 1]])\n",
        "extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(heatmap)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgrPBVNLbUV-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "samps1.max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq8f48YGz7P8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(heatmap_history)):\n",
        "  plt.figure()\n",
        "  plt.imshow(heatmap_history[i].T, origin='lower')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7S7B2lUEml4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#noise1 = torch.from_numpy(np.random.normal(0, 1/2, [batch_size, sample_size, num_noise])).float().to(device)\n",
        "#samps1 = torch.tanh(adv(torch.cat([noise1, z_rep_main], dim=2)))\n",
        "#ds = torch.sqrt(((c - samps1.repeat(1, 784, 1))**2).sum(2))\n",
        "#w = torch.softmax(ds, dim=1)\n",
        "#target = torch.bmm(w.view(batch_size, 1, 784), x.view(batch_size, 784, 1))\n",
        "#g = F(torch.cat((samps1, z_rep_main.detach()), dim=-1))\n",
        "#print(g.shape)\n",
        "#print(target.shape)\n",
        "#L_samps = -((g - target).abs()).mean(1) #- 3*lz\n",
        "#samps1 = direct_idx\n",
        "\n",
        "error_map = np.zeros([28, 28])\n",
        "for n in range(0, 10):\n",
        "  print(((locs[0, n, :5, :]+1)/2)*(img_size-1))\n",
        "  print(((locs[-1, n, :5, :]+1)/2)*(img_size-1))\n",
        "\n",
        "  \n",
        "  g = F(torch.cat((c, z_main.repeat(1, c.size(1), 1)), dim=-1))\n",
        "\n",
        "  L = (g - x).abs()\n",
        "  error_map += L.reshape(batch_size, img_size, img_size).sum(0).cpu().data.numpy()\n",
        "  print(L.shape)\n",
        "  I = L[n, :, 0].reshape(28, 28).cpu().data\n",
        "  print(I.shape)\n",
        "  plt.figure()\n",
        "  plt.subplot(131)\n",
        "  plt.imshow(I, vmin=0, vmax=1)\n",
        "  print(I.max())\n",
        "  #print(L_samps[n, :])\n",
        "  plt.subplot(132)\n",
        "  plt.imshow(x[n, :, 0].reshape(28,28,).cpu().data, vmin=0, vmax=1)\n",
        "  plt.subplot(133)\n",
        "  plt.imshow(g[n, :, 0].reshape(28,28,).cpu().data)\n",
        "  plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(error_map)\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(heatmap)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dChrO2kRTURY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx = 1\n",
        "img = x.reshape(batch_size, 28, 28, 1)\n",
        "print(torch.squeeze(img[idx, :, :, :]).shape)\n",
        "plt.figure()\n",
        "plt.imshow(torch.squeeze(img[idx, :, :, :]).cpu().data)\n",
        "\n",
        "res = 28\n",
        "c_hd = get_mgrid(res).reshape(1, res**2, 2).repeat(batch_size, 1, 1).to(device)\n",
        "print(c_hd.shape)\n",
        "g = F(torch.cat((c_hd, z_main.repeat(1, c_hd.size(1), 1)), dim=2))\n",
        "print(g.shape)\n",
        "#plt.figure()\n",
        "#plt.imshow(g[idx, :, :].reshape(res,res).cpu().data)\n",
        "\n",
        "res = 28\n",
        "c_hd = get_mgrid(res).reshape(1, res**2, 2).repeat(batch_size, 1, 1).to(device)\n",
        "print(c_hd.shape)\n",
        "g = F(torch.cat((c_hd, z_main.repeat(1, c_hd.size(1), 1)), dim=2))\n",
        "print(g.shape)\n",
        "plt.figure()\n",
        "plt.imshow(g[idx, :, :].reshape(res,res).cpu().data, vmin=0, vmax=1)\n",
        "\n",
        "target = torch.zeros(batch_size, res**2, 1).to(device)\n",
        "for i in range(res**2):\n",
        "    samps1 = c_hd[:, i, :].unsqueeze(1)\n",
        "    ds = torch.sqrt(((c - samps1.repeat(1, 784, 1))**2).sum(2))\n",
        "    w = torch.softmax(-35*ds, dim=1)\n",
        "    tmp = torch.bmm(w.view(batch_size, 1, 784), x.view(batch_size, 784, 1))\n",
        "    target[:, i, :] = tmp.squeeze().unsqueeze(1)\n",
        "\n",
        "L_samps = ((g - target).abs())\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(L_samps[idx, :].reshape(res,res).cpu().data)\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(target[idx, :, :].reshape(res, res).cpu().data, vmin=0, vmax=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-bkqN2rRePL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mg = get_mgrid(5)\n",
        "#print(mg)\n",
        "print(img[0, 24, 13])\n",
        "x_lin = x.reshape(batch_size, -1, n_channels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2ZsdWLhtcMv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set these to whatever you want for your gaussian filter\n",
        "kernel_size = 15\n",
        "sigma = 3\n",
        "channels = 1\n",
        "\n",
        "# Create a x, y coordinate grid of shape (kernel_size, kernel_size, 2)\n",
        "x_cord = torch.arange(kernel_size)\n",
        "x_grid = x_cord.repeat(kernel_size).view(kernel_size, kernel_size)\n",
        "y_grid = x_grid.t()\n",
        "xy_grid = torch.stack([x_grid, y_grid], dim=-1)\n",
        "\n",
        "mean = (kernel_size - 1)/2.\n",
        "variance = sigma**2.\n",
        "\n",
        "# Calculate the 2-dimensional gaussian kernel which is\n",
        "# the product of two gaussian distributions for two different\n",
        "# variables (in this case called x and y)\n",
        "gaussian_kernel = (1./(2.*np.pi*variance)) *\\\n",
        "                  torch.exp(\n",
        "                      -torch.sum((xy_grid - mean)**2., dim=-1) /\\\n",
        "                      (2*variance)\n",
        "                  )\n",
        "# Make sure sum of values in gaussian kernel equals 1.\n",
        "gaussian_kernel = gaussian_kernel / torch.sum(gaussian_kernel)\n",
        "\n",
        "# Reshape to 2d depthwise convolutional weight\n",
        "gaussian_kernel = gaussian_kernel.view(1, 1, kernel_size, kernel_size)\n",
        "gaussian_kernel = gaussian_kernel.repeat(channels, 1, 1, 1)\n",
        "\n",
        "gaussian_filter = nn.Conv2d(in_channels=channels, out_channels=channels,\n",
        "                            kernel_size=kernel_size, groups=channels, bias=False)\n",
        "\n",
        "gaussian_filter.weight.data = gaussian_kernel\n",
        "gaussian_filter.weight.requires_grad = False\n",
        "plt.imshow(gaussian_filter)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3LNlYHhzJj1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.autograd.set_detect_anomaly(True)\n",
        "for step in range(501):\n",
        "    # sample a batch of data\n",
        "    x, t = next(train_iterator)\n",
        "    x, t = x.to(device), t.to(device)\n",
        "    x = x.permute(0, 2, 3, 1)\n",
        "    x = x.reshape(batch_size, -1, n_channels)\n",
        "    #if step % 2 == 1:\n",
        "    #  #TODO also sample here, or just use some of c\n",
        "    #  # compute the gradients of the inner loss with respect to zeros (gradient origin)\n",
        "    #  z = torch.zeros(batch_size, 1, num_latent).to(device).requires_grad_()\n",
        "    #  z_rep = z.repeat(1,c.size(1),1)\n",
        "    #  g = F(torch.cat((c, z_rep), dim=-1))\n",
        "    #  L_inner = ((g - x)**2).sum(1).mean()\n",
        "    #  z = -torch.autograd.grad(L_inner, [z], create_graph=True, retain_graph=True)[0]\n",
        "\n",
        "    #  z_rep = z.repeat(1, c.size(1), 1)\n",
        "\n",
        "\n",
        "      # now with z as our new latent points, optimise the data fitting loss\n",
        "     # g = F(torch.cat((c, z_rep), dim=-1))\n",
        "     # L_outer = ((g - x)**2).sum(1).mean()\n",
        "     # print(L_outer)\n",
        "     # optim_main.zero_grad()\n",
        "     # L_outer.backward()\n",
        "     # optim_main.step()\n",
        "    #else:\n",
        "      #TODO also sample here, or just use some of c\n",
        "      # compute the gradients of the inner loss with respect to zeros (gradient origin)\n",
        "    z = torch.zeros(batch_size, 1, num_latent).to(device).requires_grad_()\n",
        "    z_rep_main = z.repeat(1,c.size(1),1)\n",
        "    g = F(torch.cat((c, z_rep_main), dim=-1))\n",
        "    L_inner = ((g - x)**2).sum(1).mean()\n",
        "    z_main = -torch.autograd.grad(L_inner, [z], create_graph=True, retain_graph=True)[0]\n",
        "\n",
        "    z_rep_main = z_main.repeat(1, sample_size, 1)\n",
        "\n",
        "    z_rep_adv = z_rep_main.detach().clone()\n",
        "      #g = F(torch.cat((c, z_rep_adv), dim=-1))\n",
        "      #L_inner_adv = -((g - x)**2).sum(1).mean()\n",
        "      #z_adv = -torch.autograd.grad(L_inner_adv, [z], create_graph=True, retain_graph=True)[0]\n",
        "\n",
        "      #z_rep_adv = z_adv.repeat(1, sample_size, 1)\n",
        "\n",
        "      # sample new points\n",
        "    noise = torch.from_numpy(np.random.normal(0, 10, [batch_size, sample_size, num_noise])).float().to(device)\n",
        "    samps = torch.sigmoid(adv(torch.cat([noise, z_rep_adv], dim=-1)))\n",
        "    samps_discr = torch.round(samps * img_size).long()\n",
        "    samps_discr = samps_discr[:, :, 0]*img_size + samps_discr[:, :, 1]\n",
        "    if step % 10 == 0:\n",
        "      print(samps_discr)\n",
        "\n",
        "      # now with z as our new latent points, optimise the data fitting loss\n",
        "    g = F(torch.cat((samps.detach(), z_rep_main), dim=-1))\n",
        "    L_outer = ((g - x[torch.arange(batch_size).unsqueeze(1), samps_discr.detach(), :])**2).sum(1).mean()\n",
        "    print('sampled loss')\n",
        "    print(L_outer)\n",
        "    optim_main.zero_grad()\n",
        "    L_outer.backward()\n",
        "    optim_main.step()\n",
        "\n",
        "    optim_adv.zero_grad()\n",
        "    g = F(torch.cat((samps, z_rep_main), dim=-1))\n",
        "    L_outer = ((g - x[torch.arange(batch_size).unsqueeze(1), samps_discr, :])**2).sum(1).mean()\n",
        "    L_outer.backward()\n",
        "    optim_adv.step()\n",
        "\n",
        "\n",
        "    # compute sampling statistics\n",
        "    recent_zs.append(z.detach())\n",
        "    recent_zs = recent_zs[-100:]\n",
        "\n",
        "    if step % 100 == 0 and step > 0:\n",
        "        print(f\"Step: {step}   Loss: {L_outer.item():.3f}\")\n",
        "        z_rep = z.repeat(1, c.shape[1], 1)\n",
        "        g = F(torch.cat((c, z_rep), dim=-1))\n",
        "        # plot reconstructions, interpolations, and samples\n",
        "        recons = torchvision.utils.make_grid(torch.clamp(g, 0, 1).permute(0,2,1).reshape(-1, n_channels, img_size, img_size), nrow=8)\n",
        "        slerps = torchvision.utils.make_grid(torch.clamp(slerp_batch(F, z.data, c), 0, 1).permute(0,2,1).reshape(-1, n_channels, img_size, img_size), nrow=8)\n",
        "        sample = torchvision.utils.make_grid(torch.clamp(gon_sample(F, recent_zs, c), 0, 1).permute(0,2,1).reshape(-1, n_channels, img_size, img_size))\n",
        "\n",
        "        clear_output()\n",
        "        plt.title('Reconstructions')\n",
        "        plt.imshow(recons[0,:,:].reshape(242,242,1).repeat(1,1,3).cpu().data.numpy())\n",
        "        plt.figure()\n",
        "        plt.title('Spherical Interpolations')\n",
        "        plt.imshow(slerps[0,:,:].reshape(242,242,1).repeat(1,1,3).cpu().data.numpy())\n",
        "        plt.figure()\n",
        "        plt.title('Samples')\n",
        "        plt.imshow(sample[0,:,:].reshape(242,242,1).repeat(1,1,3).cpu().data.numpy())\n",
        "        plt.show()\n",
        "        sleep(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkaR2YESzaN1",
        "colab_type": "text"
      },
      "source": [
        "**Comments:**\n",
        "\n",
        "The gradient origin network loss is:\n",
        "\n",
        "$$G_{\\mathbf{x}} = \\int \\mathcal{L} \\Big( \\Phi_{\\mathbf{x}}(\\mathbf{c}), F\\Big(\\mathbf{c} \\oplus -\\nabla_{\\mathbf{z}_0} \\int \\mathcal{L} \\big( \\Phi_{\\mathbf{x}}(\\mathbf{c}), F(\\mathbf{c} \\oplus \\mathbf{z}_0) \\big) \\mathrm{d}\\mathbf{c} \\Big) \\Big) \\mathrm{d}\\mathbf{c},$$\n",
        "\n",
        "where we first compute the gradients of the inner loss with respect to the zero vector $\\mathbf{z}_0$:\n",
        "$$\\mathbf{z}=-\\nabla_{\\mathbf{z}_0} \\int \\mathcal{L} \\big( \\Phi_{\\mathbf{x}}(\\mathbf{c}), F(\\mathbf{c} \\oplus \\mathbf{z}_0) \\big) \\mathrm{d}\\mathbf{c}.$$\n",
        "\n",
        "```\n",
        "z = torch.zeros(batch_size, 1, num_latent).to(device).requires_grad_()\n",
        "z_rep = z.repeat(1,c.size(1),1)\n",
        "g = F(torch.cat((c, z_rep), dim=-1))\n",
        "L_inner = ((g - x)**2).sum(1).mean()\n",
        "z = -torch.autograd.grad(L_inner, [z], create_graph=True, retain_graph=True)[0]\n",
        "```\n",
        "\n",
        "These gradients act as the latent space that we will call $\\mathbf{z}$. They are then concatenated $\\oplus$ to the coordinates $\\mathbf{c}$ and now we can optimise the outer loss:\n",
        "\n",
        "$$G_{\\mathbf{x}} = \\int \\mathcal{L} \\Big( \\Phi_{\\mathbf{x}}(\\mathbf{c}), F(\\mathbf{c} \\oplus \\mathbf{z} ) \\Big) \\mathrm{d}\\mathbf{c}$$\n",
        "\n",
        "```\n",
        "z_rep = z.repeat(1, c.size(1), 1)\n",
        "g = F(torch.cat((c, z_rep), dim=-1))\n",
        "L_outer = ((g - x)**2).sum(1).mean()\n",
        "optim.zero_grad()\n",
        "L_outer.backward()\n",
        "optim.step()\n",
        "```\n",
        "\n",
        "When trained, we can simply sample $\\mathbf{z}\\sim p_z$ and query the model $F(\\mathbf{c} \\oplus \\mathbf{z})$:\n",
        "\n",
        "```\n",
        "z_rep = z.repeat(1, c.size(1), 1)\n",
        "g_sampled = F(torch.cat((c, z_rep), dim=-1))\n",
        "```"
      ]
    }
  ]
}